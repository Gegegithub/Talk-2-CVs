"""
Interface Streamlit pour le Local Recruiter Assistant
Style inspirÃ© de Gemini
"""
import streamlit as st
from pathlib import Path

from config.settings import DATA_DIR
from utils.pdf_processor import PDFProcessor
from utils.vector_store import get_vector_store

# Configuration de la page
st.set_page_config(
    page_title="Local Recruiter Assistant",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ© style Gemini
st.markdown("""
<style>
    /* Masquer seulement le menu hamburger, pas le toggle sidebar */
    #MainMenu {visibility: hidden;}

    /* Container principal */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 0;
        max-width: 900px;
    }

    /* Zone de bienvenue centrÃ©e */
    .welcome-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        min-height: 50vh;
        text-align: center;
    }

    .welcome-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
    }

    .welcome-title {
        font-size: 2.2rem;
        font-weight: 400;
        color: #E8EAED;
        margin-bottom: 0.5rem;
    }

    .welcome-subtitle {
        font-size: 2.2rem;
        font-weight: 400;
        color: #9AA0A6;
        margin-bottom: 2rem;
    }

    /* Boutons de suggestions */
    .suggestion-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        gap: 0.75rem;
        margin-top: 1.5rem;
    }

    .stButton > button {
        background-color: #303134;
        color: #E8EAED;
        border: 1px solid #5F6368;
        border-radius: 24px;
        padding: 0.6rem 1.2rem;
        font-size: 0.9rem;
        transition: background-color 0.2s;
    }

    .stButton > button:hover {
        background-color: #3C4043;
        border-color: #8AB4F8;
    }

    /* Sidebar */
    [data-testid="stSidebar"] {
        background-color: #1E1E1E;
    }

    [data-testid="stSidebar"] .stMetric {
        background-color: #303134;
        padding: 1rem;
        border-radius: 12px;
    }

    /* Chat messages */
    .stChatMessage {
        background-color: transparent;
    }

    /* Source box */
    .source-box {
        background-color: #303134;
        padding: 1rem;
        border-radius: 12px;
        margin-top: 0.5rem;
    }

    /* Footer */
    .footer-text {
        text-align: center;
        color: #9AA0A6;
        font-size: 0.8rem;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)


def save_uploaded_file(uploaded_file) -> Path:
    """Sauvegarde un fichier uploadÃ© dans le dossier data/"""
    file_path = DATA_DIR / uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path


def ingest_single_pdf(pdf_path: Path) -> int:
    """IngÃ¨re un seul PDF et retourne le nombre de chunks"""
    processor = PDFProcessor()
    chunks = processor.process_pdf(pdf_path)

    if chunks:
        vectorstore = processor.vector_store.get_vectorstore()
        vectorstore.add_documents(chunks)

    return len(chunks)


# Sidebar - Statistiques (forcer l'affichage)
st.sidebar.title("ğŸ“Š Base de CVs")

with st.sidebar:
    try:
        vector_store = get_vector_store()
        stats = vector_store.get_stats()

        col1, col2 = st.columns(2)
        with col1:
            st.metric("CVs indexÃ©s", stats["total_chunks"] // 5 or 0)  # Approximation
        with col2:
            status_emoji = "ğŸŸ¢" if stats["status"] == "ready" else "ğŸ”´"
            st.metric("Statut", status_emoji)

        if stats["total_chunks"] > 0:
            with st.expander("âš™ï¸ Options"):
                if st.button("ğŸ—‘ï¸ Vider la base", use_container_width=True):
                    vector_store.reset()
                    st.rerun()

    except Exception as e:
        st.error(f"Erreur : {e}")

    st.divider()

    st.markdown("### ğŸ’¡ Exemples")
    st.caption("â€¢ Qui maÃ®trise Python et SQL ?")
    st.caption("â€¢ Trouve un profil Data Engineer")
    st.caption("â€¢ ExpÃ©rience en Machine Learning ?")

    st.divider()
    st.caption("ğŸ”’ 100% Local - RGPD Compliant")
    st.caption("ğŸ¤– Ollama (Llama 3.1)")
    st.caption("ğŸ’¾ ChromaDB + LangChain")


# Initialiser l'historique
if "messages" not in st.session_state:
    st.session_state.messages = []

# Zone principale
if not st.session_state.messages:
    # Ã‰cran d'accueil style Gemini
    st.markdown("""
    <div class="welcome-container">
        <div class="welcome-icon">ğŸ¯</div>
        <div class="welcome-title">Bonjour,</div>
        <div class="welcome-subtitle">Trouvons le candidat idÃ©al</div>
    </div>
    """, unsafe_allow_html=True)

    # Boutons de suggestions
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if st.button("ğŸ Expert Python", use_container_width=True):
            st.session_state.suggestion = "Qui a de l'expÃ©rience en Python ?"
            st.rerun()

    with col2:
        if st.button("ğŸ¤– Machine Learning", use_container_width=True):
            st.session_state.suggestion = "Trouve les profils Machine Learning"
            st.rerun()

    with col3:
        if st.button("â˜ï¸ Cloud & DevOps", use_container_width=True):
            st.session_state.suggestion = "Qui maÃ®trise le Cloud ou DevOps ?"
            st.rerun()

    with col4:
        if st.button("ğŸ“Š Data Engineer", use_container_width=True):
            st.session_state.suggestion = "Trouve un profil Data Engineer"
            st.rerun()

else:
    # Afficher l'historique des messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            if message["role"] == "assistant" and "sources" in message:
                if message["sources"]:
                    with st.expander("ğŸ“ Sources consultÃ©es"):
                        for source in message["sources"]:
                            st.write(f"**{source['file']}** (chunk {source['chunk_id']})")
                            st.caption(source['preview'])

# Input utilisateur avec Ã©pingle pour fichiers
chat_input = st.chat_input(
    "Posez votre question ou attachez des CVs ğŸ“",
    accept_file="multiple",
    file_type=["pdf"]
)

# Traiter une suggestion cliquÃ©e
if "suggestion" in st.session_state:
    prompt = st.session_state.suggestion
    del st.session_state.suggestion

    from agents.recruiter_rag import answer

    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Recherche..."):
            try:
                result = answer(prompt, st.session_state.messages)
                response = result["answer"]
                sources = result.get("sources", [])

                st.markdown(response)

                if sources:
                    with st.expander("ğŸ“ Sources consultÃ©es"):
                        for source in sources:
                            st.write(f"**{source['file']}** (chunk {source['chunk_id']})")
                            st.caption(source['preview'])

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response,
                    "sources": sources
                })
            except Exception as e:
                st.error(f"âŒ Erreur : {e}")

# Traiter l'input du chat
if chat_input:
    prompt = chat_input.text if hasattr(chat_input, 'text') else str(chat_input)
    files = chat_input.files if hasattr(chat_input, 'files') else None

    # Traiter les fichiers uploadÃ©s
    if files:
        total_chunks = 0
        file_names = []

        for uploaded_file in files:
            file_path = save_uploaded_file(uploaded_file)
            chunks_count = ingest_single_pdf(file_path)
            total_chunks += chunks_count
            file_names.append(uploaded_file.name)

        upload_msg = f"âœ… {len(files)} CV(s) importÃ©(s) : {', '.join(file_names)}"
        st.session_state.messages.append({"role": "assistant", "content": upload_msg})

        with st.chat_message("assistant"):
            st.success(upload_msg)

    # Traiter la question
    if prompt and prompt.strip():
        from agents.recruiter_rag import answer

        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ” Recherche dans les CVs..."):
                try:
                    result = answer(prompt, st.session_state.messages)
                    response = result["answer"]
                    sources = result.get("sources", [])

                    st.markdown(response)

                    if sources:
                        with st.expander("ğŸ“ Sources consultÃ©es"):
                            for source in sources:
                                st.write(f"**{source['file']}** (chunk {source['chunk_id']})")
                                st.caption(source['preview'])

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response,
                        "sources": sources
                    })
                except Exception as e:
                    st.error(f"âŒ Erreur : {e}")

    if files:
        st.rerun()
