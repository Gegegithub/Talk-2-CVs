# Configuration Ollama
OLLAMA_MODEL=mistral
# Alternatives : llama3.1, llama2, codellama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TEMPERATURE=0.1

# Configuration Embeddings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Alternative pour multilingue : intfloat/multilingual-e5-base

# Configuration RAG
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=5
